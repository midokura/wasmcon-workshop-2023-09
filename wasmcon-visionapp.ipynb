{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Vision Sensing Application](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In this notebook, we will develop and deploy face detection application to Raspberry Pi4. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Vision Sensing Application](#toc1_1_)    \n",
    "    - [Prepare Environment](#toc1_1_1_)    \n",
    "    - [Run Wasm Application](#toc1_1_2_)    \n",
    "    - [Wasi-Sensor](#toc1_1_3_)    \n",
    "    - [Deploy Wasm module to Device](#toc1_1_4_)    \n",
    "    - [Change the application behavior by sending the command](#toc1_1_5_)    \n",
    "    - [Composite Wasm modules](#toc1_1_6_)    \n",
    "  - [Thank you for joining the hands-on !](#toc1_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_1_'></a>[Prepare Environment](#toc0_)\n",
    "\n",
    "Download the AI model. Today, we use our own TFlite model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import os\n",
    "\n",
    "# Suppress the warning of TFlite\n",
    "os.environ['PYTHONUNBUFFERED'] = '1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "os.dup2(1, 0)\n",
    "\n",
    "MODEL_URL=f\"http://localhost:4000/face_detection_mobilenet_v2_ssd_lite_fpn_quant.tflite\"\n",
    "MODEL = '/assets/detection.tflite'\n",
    "with open(file=os.path.join(MODEL), mode=\"wb\") as model_blob:\n",
    "    download_stream = urlopen(MODEL_URL)\n",
    "    model_blob.write(download_stream.read())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the image for inference. Resize the image to 300x300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IMAGE_URL=f\"http://localhost:4000/photo_4-1.jpg\"\n",
    "IMAGE = \"./assets/face.png\"\n",
    "with open(file=os.path.join(IMAGE), mode=\"wb\") as image_blob:\n",
    "    download_stream = urlopen(IMAGE_URL)\n",
    "    image_blob.write(download_stream.read())\n",
    "\n",
    "image = cv2.cvtColor(cv2.imread(IMAGE), cv2.COLOR_BGR2RGB)\n",
    "# Crop [start_row:end_row, start_col:end_col]\n",
    "image = image[20:320, 330:630] \n",
    "image = cv2.resize(image, dsize=(300, 300))\n",
    "\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so we have the Model and the Image.\n",
    "Let's build the prepared wasm module using VASDK CLI. \n",
    "\n",
    "First, please go to ```http://<your-designated-raspberrypi-host>:9000``` and make note of your IP address, which you will copy back here. Also, click there on your designated target port.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The IP address you copied from the previous webpage\n",
    "IP_ADDR = input('Please put your IP address: 10.42.0.1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import redirect_stdout\n",
    "import os\n",
    "\n",
    "if not IP_ADDR:\n",
    "    raise Exception('Please type your IP address into IP_ADDR in the previous cell')\n",
    "\n",
    "APP_WORK_SPACE = 'samples/detection-single'\n",
    "VISION_APP = APP_WORK_SPACE + '/bin/node.wasm'\n",
    "with redirect_stdout(open(os.devnull, 'w')):\n",
    "# Since Raspberry Pi 4 is arm64, build wasm and AoT for arm64\n",
    "    ! vasdk-cli config set webserver.host=$IP_ADDR\n",
    "    ! cd $APP_WORK_SPACE && vasdk-cli build arm64\n",
    "print(\"build done\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check inside. In this wasm module, there are *Sensor I/F*, *OpenCV I/F*, *Wasi-NN I/F*.\n",
    "\n",
    "This code is monolithic. Get frames from the camera using Sensor I/F, preprocess image using OpenCV I/F, compute inference using Wasi-NN I/F, and finally report the result using Telemetry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wasm2wat $VISION_APP | grep 'import \"'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of import functions that we have to load from native libraries in the Device.  So, let's set up the device mock environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evp_mock.mock import evp\n",
    "from senscord_mock.mock import senscord\n",
    "from nn_mock.tflite import wasi_nn\n",
    "import numpy as np\n",
    "\n",
    "MODEL=\"/assets/detection.tflite\"\n",
    "# Specify raspicamv3 camera\n",
    "stream = \"raspicam_image_stream.0\"\n",
    "\n",
    "# Instantiate the mock EVP and SensCord\n",
    "evp_mock = evp.MockEVP()\n",
    "sensor_mock = senscord.MockSenscord()\n",
    "wasi_nn_mock = wasi_nn.WASI_NN(MODEL)\n",
    "\n",
    "# Back door setting\n",
    "sensor_mock.set_input(image)\n",
    "wasi_nn_mock.set_input(np.expand_dims(image.astype(np.float32) / 255.0, axis=0))\n",
    "\n",
    "# Specify raspicam v3\n",
    "stream = \"raspicam_image_stream.0\"\n",
    "p_param_str = f\"{{\\\"stream\\\":\\\"{stream}\\\",\\\"model\\\":\\\"{MODEL_URL}\\\"}}\"\n",
    "e = evp.EVPRpc(method=\"config\", params=p_param_str)\n",
    "evp_mock.injectEvent(e)\n",
    "\n",
    "# Let's immediately stop for just one frame test\n",
    "e = evp.EVPShutdown()   \n",
    "evp_mock.injectEvent(e)  \n",
    "\n",
    "e = evp.EVPShutdown()   \n",
    "evp_mock.injectEvent(e)  \n",
    "print(\"mock environment is ready\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_2_'></a>[Run Wasm Application](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Wasm Vision and Sensing Application and see what happened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from node.api import Node\n",
    "\n",
    "# Start the wasm app \n",
    "node = Node()\n",
    "\n",
    "# Register the native symbols\n",
    "node.register_natives(evp_mock, sensor_mock)\n",
    "node.register_nn(wasi_nn_mock)\n",
    "\n",
    "# Load and instantiate the wasm app\n",
    "node.load_module(VISION_APP)\n",
    "\n",
    "# If you want to debug the wasm app, uncomment the following line\n",
    "# node.start_debugging()\n",
    "node.main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is [detection_single code](samples/detection-single/node/draw_bbox.c). You can modify the contents.\n",
    "\n",
    "Next, let's run wasm application with debugger and deep dive into the code. In this time, let me introduce the process by reffering the code with debugger."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's rerun wasm application with the LLDB debugger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from node.api import Node\n",
    "\n",
    "p_param_str = f\"{{\\\"stream\\\":\\\"{stream}\\\",\\\"model\\\":\\\"{MODEL_URL}\\\"}}\"\n",
    "e = evp.EVPRpc(method=\"config\", params=p_param_str)\n",
    "evp_mock.injectEvent(e)\n",
    "\n",
    "# Let's immediately stop for just one frame test\n",
    "# Put the shutdown command in queue\n",
    "e = evp.EVPShutdown()\n",
    "evp_mock.injectEvent(e)  \n",
    "e = evp.EVPShutdown()\n",
    "evp_mock.injectEvent(e)  \n",
    "\n",
    "# Start the wasm app \n",
    "node = Node()\n",
    "\n",
    "# Register the native symbols\n",
    "node.register_natives(evp_mock, sensor_mock)\n",
    "node.register_nn(wasi_nn_mock)\n",
    "\n",
    "# Load and instantiate the wasm app\n",
    "node.load_module(VISION_APP)\n",
    "\n",
    "# If you want to debug the wasm app, uncomment the following line\n",
    "node.start_debugging()\n",
    "node.main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select Run->Start Debugging and select \"WAMR-Attach\", you can start LLDB debugger. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_3_'></a>[Wasi-Sensor](#toc0_)\n",
    "\n",
    "Next, we will deploy exactly same application to Raspberry Pi4.\n",
    "\n",
    "Thanks to the abstracted Sensor I/F, we can seemlessly move to other device environment.\n",
    "Imagine being able to deploy your application to any device you want. This is where the **<span style=\"color:#FFF020\">WASI-sensor</span>** interface we are currently developing comes into the conversation.\n",
    "It is targeting 1D(accerarator, GNSS) to 3D(IMU, Depth) Sensors to be controlled from Wasm.\n",
    "\n",
    "![wasi-sensor](images/Advanced_Hands-on/wasi-sensor.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_4_'></a>[Deploy Wasm module to Device](#toc0_)\n",
    "\n",
    "OK, Let's deploy wasm application to Raspberry Pi4. \n",
    "Go ahead and undeploy previous wasm application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! vasdk-cli deploy -e"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then check status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! vasdk-cli get deployment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we deploy detection application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "APP_WORK_SPACE = 'samples/detection-single'\n",
    "! cd $APP_WORK_SPACE && vasdk-cli -v deploy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the status of the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! vasdk-cli get deployment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify which stream(sensor) to use. In this case, we use *raspicam_image_stream.0*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "stream = \"raspicam_image_stream.0\"\n",
    "MODEL_URL=f\"http://{IP_ADDR}:4000/face_detection_mobilenet_v2_ssd_lite_fpn_quant.tflite\"\n",
    "\n",
    "# send a message to the wasm app\n",
    "config = f\"{{\\\"stream\\\":\\\"{stream}\\\",\\\"model\\\":\\\"{MODEL_URL}\\\"}}\"\n",
    "param_str = f\"'{config}'\"\n",
    "! vasdk-cli rpc node \"config\" $param_str"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. Now application is running. Let's check telemetry to see face is detected or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! vasdk-cli get telemetry"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the image by using debug viewer. Please open your Browser and access the URL. The window which has your github name will be there.\n",
    "\n",
    "[http://<<raspi_ip_adder>>:3000](http://192.168.1.62:3000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_5_'></a>[Change the application behavior by sending the command](#toc0_)\n",
    "Let's change the color of bounding box to red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! vasdk-cli rpc node \"rgb\" \"FF0000\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and change the picture quality via VASDK CLI.\n",
    "\n",
    "Change Saturation to 0. (Default is 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! vasdk-cli rpc node \"saturation\" \"255\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change Brightness. (Default is 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! vasdk-cli rpc node \"brightness\" \"0\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the contrast. (Default is 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! vasdk-cli rpc node \"contrast\" \"0\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. application run !! **<span style=\"color:#FFF020\">Congratulation !</span>**\n",
    "\n",
    "But we know what you feel: Is it an effortless development environment ?  Answer is **<span style=\"color:#FFF020\">NO</span>**.\n",
    "\n",
    "### <a id='toc1_1_6_'></a>[Composite Wasm module](#toc0_)\n",
    "\n",
    "We have another type of Vision Sensing Application based on \"Nano Process Vision\".\n",
    "\n",
    "[Composite Wasm module for Detection](samples/detection/README.md) is describing the detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "from contextlib import redirect_stdout\n",
    "import os\n",
    "APP_WORK_SPACE = 'samples/detection'\n",
    "\n",
    "with redirect_stdout(open(os.devnull, 'w')):\n",
    "    ! vasdk-cli config set webserver.host=$IP_ADDR\n",
    "    ! cd $APP_WORK_SPACE && vasdk-cli build arm64\n",
    "print(\"build done\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check one of the wasm module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! wasm2wat $APP_WORK_SPACE/bin/inference_wasi_nn.wasm | grep '(import '"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now obviously dependency on environment is reduced. Reusability and testability is improved.\n",
    "\n",
    "Each wasm module is loosely connected by topic using the Pub/Sub Messaging pattern.\n",
    "\n",
    "Let's deploy them to Raspberry Pi4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! vasdk-cli deploy -e"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the deployment status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! vasdk-cli get deployment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's deploy now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "APP_WORK_SPACE = 'samples/detection'\n",
    "! cd $APP_WORK_SPACE && vasdk-cli -v deploy -t 40"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the deployment status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! vasdk-cli get deployment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send RPC command to each wasm module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Specify stream(sensor)\n",
    "stream = \"raspicam_image_stream.0\"\n",
    "! vasdk-cli -d rpc senscord_source config $stream\n",
    "\n",
    "# Specify the location of Model\n",
    "MODEL_URL=f\"http://{IP_ADDR}:4000/face_detection_mobilenet_v2_ssd_lite_fpn_quant.tflite\"\n",
    "! vasdk-cli -d rpc inference_wasi_nn config \"http${MODEL_URL}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the inference result. Is it really same as monolithic version ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Thank you for joining the hands-on !](#toc0_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e6a8208b5c026a8c0de9425c389826232a6a2d0a5827555e10540e38d8b94bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
