{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Sensing Application"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will develop and deploy face detection application to Raspberry Pi4. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead and undeploy previous application from Raspberry pi4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wedge-cli deploy -e"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Face Detection model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import os\n",
    "\n",
    "MODEL_URL=f\"https://tonibc.blob.core.windows.net/vsa/face_detection_mobilenet_v2_ssd_lite_fpn_quant.tflite?sp=r&st=2023-07-16T21:23:44Z&se=2024-10-01T05:23:44Z&spr=https&sv=2022-11-02&sr=b&sig=q8rvTt9Kh3rNmWDLje%2BMtk8E1%2FXVuxM1Nh2lOq%2F8ctE%3D\"\n",
    "MODEL = '/assets/detection.tflite'\n",
    "with open(file=os.path.join(MODEL), mode=\"wb\") as model_blob:\n",
    "    download_stream = urlopen(MODEL_URL)\n",
    "    model_blob.write(download_stream.read())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the image for inference. Resize the image to 300x300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IMAGE_URL=f\"https://ps.nikkei.com/catalonia2105/images/photo_4-1.jpg\"\n",
    "IMAGE = \"./assets/face.png\"\n",
    "with open(file=os.path.join(IMAGE), mode=\"wb\") as image_blob:\n",
    "    download_stream = urlopen(IMAGE_URL)\n",
    "    image_blob.write(download_stream.read())\n",
    "\n",
    "image = cv2.cvtColor(cv2.imread(IMAGE), cv2.COLOR_BGR2RGB)\n",
    "# Crop [start_row:end_row, start_col:end_col]\n",
    "image = image[20:320, 330:630] \n",
    "image = cv2.resize(image, dsize=(300, 300))\n",
    "\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the device mock environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evp_mock.mock import evp\n",
    "from senscord_mock.mock import senscord\n",
    "from nn_mock.tflite import wasi_nn\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ['PYTHONUNBUFFERED'] = '1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "MODEL=\"/assets/detection.tflite\"\n",
    "\n",
    "# Instantiate the mock EVP and SensCord\n",
    "evp_mock = evp.MockEVP()\n",
    "sensor_mock = senscord.MockSenscord()\n",
    "wasi_nn_mock = wasi_nn.WASI_NN(MODEL)\n",
    "\n",
    "#back door setting\n",
    "sensor_mock.set_input(image)\n",
    "wasi_nn_mock.set_input(np.expand_dims(image.astype(np.float32) / 255.0, axis=0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so we have the model and the image.\n",
    "Let's build the WebAssembly module for face detection model using WEdge CLI. WEdge CLI will generate the deployment manifest to deploy the application to Raspberry Pi4 for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_WORK_SPACE = 'samples/detection-single'\n",
    "VISION_APP = APP_WORK_SPACE + '/bin/node.wasm'\n",
    "IP_ADDR='192.168.1.61'\n",
    "\n",
    "# Since Raspberry Pi 4 is arm64, build wasm and AoT for arm64\n",
    "! wedge-cli config set webserver.host=$IP_ADDR\n",
    "! cd $APP_WORK_SPACE && wedge-cli build arm64\n",
    "! wedge-cli config set webserver.host=localhost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare the commands in the event queue in advance. You can set it for any time you like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify raspicamv3\n",
    "stream = \"raspicam_image_stream.0\"\n",
    "MODEL_URL=f\"https://tonibc.blob.core.windows.net/vsa/face_detection_mobilenet_v2_ssd_lite_fpn_quant.tflite?sp=r&st=2023-07-16T21:23:44Z&se=2024-10-01T05:23:44Z&spr=https&sv=2022-11-02&sr=b&sig=q8rvTt9Kh3rNmWDLje%2BMtk8E1%2FXVuxM1Nh2lOq%2F8ctE%3D\"\n",
    "\n",
    "# send a message to the wasm app\n",
    "p_param_str = f\"{{\\\"stream\\\":\\\"{stream}\\\",\\\"model\\\":\\\"{MODEL_URL}\\\"}}\"\n",
    "# put in queue\n",
    "e = evp.EVPRpc(method=\"config\", params=p_param_str)\n",
    "evp_mock.injectEvent(e)\n",
    "\n",
    "# let's immidately stop for just one frame test\n",
    "e = evp.EVPShutdown()\n",
    "evp_mock.injectEvent(e)  \n",
    "\n",
    "# put the shut down command in queue\n",
    "e = evp.EVPShutdown()\n",
    "evp_mock.injectEvent(e)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Wasm Vision and Sensing Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from node.api import Node\n",
    "\n",
    "# start the wasm app \n",
    "node = Node()\n",
    "\n",
    "# register the native symbols\n",
    "node.register_natives(evp_mock, sensor_mock)\n",
    "node.register_nn(wasi_nn_mock)\n",
    "\n",
    "# load and instantiate the wasm app\n",
    "node.load_module(VISION_APP)\n",
    "\n",
    "# if you want to debug the wasm app, uncomment the following line\n",
    "node.start_debugging()\n",
    "node.main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, Let's deploy wasm application to Raspberry Pi4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_WORK_SPACE = 'samples/detection-single'\n",
    "! cd $APP_WORK_SPACE && wedge-cli deploy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the status of the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state/$agent/report-status-interval-min': 3, 'state/$agent/report-status-interval-max': 3, 'systemInfo': {'os': 'Linux', 'arch': 'aarch64', 'evp_agent': 'v1.15.0', 'protocolVersion': 'EVP2-TB'}, 'deploymentStatus': {'instances': {'node': {'status': 'ok', 'moduleId': 'node'}}, 'modules': {'node': {'status': 'ok'}}, 'deploymentId': 'detection-single-wasm', 'reconcileStatus': 'ok'}}\n",
      "{}\n",
      "{'state/$agent/report-status-interval-min': 3, 'state/$agent/report-status-interval-max': 3, 'systemInfo': {'os': 'Linux', 'arch': 'aarch64', 'evp_agent': 'v1.15.0', 'protocolVersion': 'EVP2-TB'}, 'deploymentStatus': {'instances': {'node': {'status': 'ok', 'moduleId': 'node'}}, 'modules': {'node': {'status': 'ok'}}, 'deploymentId': 'detection-single-wasm', 'reconcileStatus': 'ok'}}\n",
      "{}\n",
      "{'state/$agent/report-status-interval-min': 3, 'state/$agent/report-status-interval-max': 3, 'systemInfo': {'os': 'Linux', 'arch': 'aarch64', 'evp_agent': 'v1.15.0', 'protocolVersion': 'EVP2-TB'}, 'deploymentStatus': {'instances': {'node': {'status': 'ok', 'moduleId': 'node'}}, 'modules': {'node': {'status': 'ok'}}, 'deploymentId': 'detection-single-wasm', 'reconcileStatus': 'ok'}}\n",
      "{}\n",
      "{'state/$agent/report-status-interval-min': 3, 'state/$agent/report-status-interval-max': 3, 'systemInfo': {'os': 'Linux', 'arch': 'aarch64', 'evp_agent': 'v1.15.0', 'protocolVersion': 'EVP2-TB'}, 'deploymentStatus': {'instances': {'node': {'status': 'ok', 'moduleId': 'node'}}, 'modules': {'node': {'status': 'ok'}}, 'deploymentId': 'detection-single-wasm', 'reconcileStatus': 'ok'}}\n",
      "{}\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "! wedge-cli get deployment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify which stream to use. In this case, we use raspicam_image_stream.0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = \"raspicam_image_stream.0\"\n",
    "MODEL_URL=f\"https://tonibc.blob.core.windows.net/vsa/face_detection_mobilenet_v2_ssd_lite_fpn_quant.tflite?sp=r&st=2023-07-16T21:23:44Z&se=2024-10-01T05:23:44Z&spr=https&sv=2022-11-02&sr=b&sig=q8rvTt9Kh3rNmWDLje%2BMtk8E1%2FXVuxM1Nh2lOq%2F8ctE%3D\"\n",
    "\n",
    "# send a message to the wasm app\n",
    "config = f\"{{\\\"stream\\\":\\\"{stream}\\\",\\\"model\\\":\\\"{MODEL_URL}\\\"}}\"\n",
    "param_str = f\"'{config}'\"\n",
    "! wedge-cli rpc node \"config\" $param_str"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, the application is running. Let's check the result. Please open your Browser and access to the URL below.\n",
    "\n",
    "http://<<Raspberry Pi4's Domain or IP address>>:3000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the color of bounding box to red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wedge-cli rpc node \"rgb\" \"0000FF\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go agead and change the picture quality via WEdge CLI.\n",
    "\n",
    "Change Saturation to 0. (Default is 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wedge-cli rpc node \"saturation\" \"255\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change Brightness. (Default is 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wedge-cli rpc node \"brightness\" \"0\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the contrast. (Default is 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wedge-cli rpc node \"contrast\" \"128\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e6a8208b5c026a8c0de9425c389826232a6a2d0a5827555e10540e38d8b94bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
